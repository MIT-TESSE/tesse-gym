{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disclaimer\n",
    "\n",
    "Distribution authorized to U.S. Government agencies and their contractors. Other requests for this document shall be referred to the MIT Lincoln Laboratory Technology Office.\n",
    "\n",
    "This material is based upon work supported by the Under Secretary of Defense for Research and Engineering under Air Force Contract No. FA8702-15-D-0001. Any opinions, findings, conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the Under Secretary of Defense for Research and Engineering.\n",
    "\n",
    "Â© 2019 Massachusetts Institute of Technology.\n",
    "\n",
    "The software/firmware is provided to you on an As-Is basis\n",
    "\n",
    "Delivered to the U.S. Government with Unlimited Rights, as defined in DFARS Part 252.227-7013 or 7014 (Feb 2014). Notwithstanding any copyright notice, U.S. Government rights in this work are defined by DFARS 252.227-7013 or DFARS 252.227-7014 as detailed above. Use of this work other than as specifically authorized by the U.S. Government may violate any copyrights that exist in this work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treasure Hunt Challenge\n",
    "Train an agent to find 'treasures' placed around a TESSE environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines.common.policies import CnnLstmPolicy\n",
    "from stable_baselines.common.vec_env import SubprocVecEnv, VecVideoRecorder, DummyVecEnv\n",
    "from stable_baselines import PPO2\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from tesse.msgs import *\n",
    "from tesse_gym.navigation import Navigation\n",
    "from tesse_gym.treasure_hunt import TreasureHunt\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path to TESSE build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'TESSE_BUILD_PATH'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save checkpoints here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = Path('results/treasure-hunt-agent')\n",
    "log_dir.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent training\n",
    "\n",
    "This section contains code to train an agent using PPO2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_cameras(tesse_interface):\n",
    "    tesse_interface.env.request(SetCameraParametersRequest(camera=Camera.RGB_LEFT, \n",
    "                                                           height_in_pixels=240, \n",
    "                                                           width_in_pixels=320, \n",
    "                                                           field_of_view=45, \n",
    "                                                           near_clip_plane=0.05, \n",
    "                                                           far_clip_plane=50))\n",
    "    tesse_interface.env.request(SetCameraParametersRequest(camera=Camera.SEGMENTATION, \n",
    "                                                           height_in_pixels=240, \n",
    "                                                           width_in_pixels=320, \n",
    "                                                           field_of_view=45, \n",
    "                                                           near_clip_plane=0.05, \n",
    "                                                           far_clip_plane=50))\n",
    "    tesse_interface.env.request(SetCameraPositionRequest(camera=Camera.RGB_LEFT, \n",
    "                                                         x=0, \n",
    "                                                         y=0, \n",
    "                                                         z=-0.1))\n",
    "    tesse_interface.env.request(SetCameraPositionRequest(camera=Camera.SEGMENTATION, \n",
    "                                                         x=0, \n",
    "                                                         y=0, \n",
    "                                                         z=-0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callback to save checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint_callback(local_vars,  global_vars):\n",
    "    total_updates = local_vars['update'] \n",
    "    if total_updates % 50 == 0:\n",
    "        local_vars[\"self\"].save(str(log_dir / f'{total_updates:09d}.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_timesteps = 100000       # total training iterations\n",
    "scene_id = 5                   # small decluttered office\n",
    "success_dist = 2               # distance from target to be considered found\n",
    "n_targets = 50                 # number of targets spawned in scene\n",
    "max_steps = 100                # max episode length\n",
    "hunt_mode = HuntMode.MULTIPLE  # find as many targets as possible\n",
    "                               # As opposed to only having to find one\n",
    "    \n",
    "def make_unity_env(filename, num_env, base_id):\n",
    "    \"\"\" Create a wrapped Unity environment. \"\"\"\n",
    "    def make_env(rank):\n",
    "        def _thunk():\n",
    "            env = TreasureHunt(filename, \n",
    "                                'localhost',\n",
    "                                'localhost', \n",
    "                                max_steps=max_steps,\n",
    "                                worker_id=rank, \n",
    "                                step_rate=30,\n",
    "                                scene_id=scene_id,\n",
    "                                n_targets=n_targets,\n",
    "                                success_dist = success_dist,\n",
    "                                init_hook=set_cameras,\n",
    "                                hunt_mode=hunt_mode,\n",
    "                                target_found_reward=1)\n",
    "            return env\n",
    "        return _thunk\n",
    "    \n",
    "    return SubprocVecEnv([make_env(i + base_id) for i in range(num_env)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we launch environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = make_unity_env(filename, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the agent model for learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO2(CnnLstmPolicy, env, verbose=1, tensorboard_log=\"./tensorboard/\", nminibatches=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=total_timesteps, callback=save_checkpoint_callback, \n",
    "            reset_num_timesteps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(log_dir + \"the.policy\")  # save finals policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a video\n",
    "\n",
    "Demonstrates loading the model and executing it to construct a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO2.load('the.policy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_length = 500\n",
    "\n",
    "video_env = VecVideoRecorder(env,\n",
    "                             video_folder='videos',\n",
    "                             record_video_trigger=lambda x: x == 0,\n",
    "                             video_length=video_length,\n",
    "                             name_prefix='tesse'\n",
    "                            )\n",
    "\n",
    "obs = video_env.reset()\n",
    "for _ in range(video_length + 1):\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, _, _, _ = video_env.step(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random tests\n",
    "\n",
    "This just includes a few simple test snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TreasureHuntEnv(filename, 'localhost', 'localhost', worker_id = 25, scene_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    env.reset()\n",
    "    time.sleep(.2)\n",
    "    for _ in range(35):\n",
    "        (obs, reward, done, _) = env.step(0)\n",
    "        if done:\n",
    "            print(\"collision\", i)\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tess_gym]",
   "language": "python",
   "name": "conda-env-tess_gym-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
